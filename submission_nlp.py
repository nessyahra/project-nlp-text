# -*- coding: utf-8 -*-
"""submission NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11eipzBU5OmwOGHi2Oxg94Op_t9M-pnPO

# **Proyek NLP LSTM**

*   **Nama:** Venessa Yumadila Syahra
*   **ID Dicoding:** nessasyahra
"""

import nltk
nltk.download('stopwords')
nltk.download('punkt')

import pandas as pd
data = pd.read_csv('bbc-text.csv')
data.tail()

data.category.value_counts()

"""### Pre-processing"""

data['text'] = data['text'].astype(str)

# remove special characters
import re
data['text'] = data['text'].str.replace("[.,:;+!\-_<^/=?\"'\(\)\d\&*]", " ")

# make all text lowercase
data['text'] = data['text'].apply(lambda x: x.lower())

# stopwords
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

remove = set(stopwords.words('english'))
tokens = word_tokenize(str(data['text']))
filtered = [w for w in tokens if not w.lower() in remove]

# tokenizer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=50000, oov_token='<oov>')
tokenizer.fit_on_texts(data['text'].values)

x = tokenizer.texts_to_sequences(data['text'].values)
x = pad_sequences(x, maxlen=3000)

y = pd.get_dummies(data['category'], columns=data['category']).values

# split training and testing
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""### Model"""

import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(50000, 100, input_length=3000),
    tf.keras.layers.SpatialDropout1D(0.2),
    tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),
    tf.keras.layers.Dense(5, activation='softmax')
])
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

from keras.callbacks import EarlyStopping
hist = model.fit(x_train, y_train, epochs=7, batch_size=64,
                 validation_data=(x_test, y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])

"""### Plot"""

import matplotlib.pyplot as plt

# plot loss
plt.plot(hist.history['loss'])
plt.title('Plot Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='upper right')
plt.show()

# plot akurasi
plt.plot(hist.history['accuracy'])
plt.title('Plot Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()
